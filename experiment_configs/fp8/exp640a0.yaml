checkpoints:
  checkpoint_interval: 5000
  checkpoints_path: /fsx/phuc/new_workspace/experiments/fp8_for_nanotron/exp640a0/checkpoints/
  checkpoints_path_is_shared_file_system: false
  # resume_checkpoint_path: /fsx/phuc/new_workspace/experiments/fp8_for_nanotron/exp608bb1_100m_bfloat16_with_adam_epsilon_1.0e-8_and_smol_ds_but_tp8_and_dp10_and_mbs_2560_and_gbs_1.6m_and_100b_tokens_and_70k_steps_with_new_dclm_subset/checkpoints/
  save_initial_state: false


data_stages:
- data:
    dataset:
      dataloader_type: cyclic
      dataset_max_tokens: null
      dataset_weights:
      - 70
      - 15
      - 6
      - 3
      - 5
      - 1
      datasets:
      - filename_pattern: .*.ds
        # folder: /fsx/loubna/tokenized_for_exps/cosmo2_training_data/FineWeb-Edu-dedup_merged
        folder: /fsx/elie_bakouch/data/smollmv1
        # seed: 6
        # shuffle: true
        skip_tokens: 0
      - filename_pattern: .*.ds
        folder: /fsx/loubna/tokenized_for_exps/cosmo2_training_data/Cosmopedia-v2_merged
        # seed: 6
        # shuffle: true
        skip_tokens: 0
      - filename_pattern: .*.ds
        folder: /fsx/loubna/tokenized_for_exps/cosmo2_training_data/Open-Web-Math-fix_merged
        # seed: 6
        # shuffle: true
        skip_tokens: 0
      - filename_pattern: .*.ds
        folder: /fsx/loubna/tokenized_for_exps/stack_edu/starcoder2data-score-4-plus-cosmo_merged
        # seed: 6
        # shuffle: true
        skip_tokens: 0
      - filename_pattern: .*\.ds$
        # folder: /fsx/loubna/tokenized_for_exps/stack_edu/starcoder2data-score=3-cosmo-fix_merged
        folder: /fsx/loubna/tokenized_for_exps/python-edu/python-edu-8B
        seed: 6
        shuffle: true
        skip_tokens: 0
      - filename_pattern: .*\.ds$
        folder: /fsx/loubna/tokenized_for_exps/cosmo2_training_data/StackOverflow_merged
        seed: 6
        shuffle: true
        skip_tokens: 0
      pad_samples_to_global_batch_size: false
      skip_in_stream: true
    num_loading_workers: 0
    seed: 6
  name: stable
  start_training_step: 1

data_stages:
- data:
    dataset:
      dataloader_type: single
      dataset_max_tokens: null
      dataset_weights:
      - 0.5
      - 0.4
      - 0.1
      datasets:
      - filename_pattern: .*.ds
        folder: /fsx/loubna/tokenized_for_exps/fw_edu/fineweb-edu-full-cosmo2_merged
        skip_tokens: 0
      - filename_pattern: .*.ds
        # NOTE: lobuna deleted it
        # folder: /fsx/loubna/tokenized_for_exps/fw_edu/dclm-3T-cosmo2_merged
        folder: /fsx/phuc/datasets/100b_smol_ds/fw_edu_dclm_subset
        skip_tokens: 0
      - filename_pattern: .*.ds
        folder: /fsx/loubna/tokenized_for_exps/fw_edu/starcoderdata-full-cosmo_merged
        skip_tokens: 0
      pad_samples_to_global_batch_size: false
      skip_in_stream: true
    num_loading_workers: 0
    seed: 42
  name: Stable Training Stage
  start_training_step: 1

experiment_logger:
  tensorboard_logger:
    flush_secs: 30
    tensorboard_dir: fsx/phuc/new_workspace/experiments/fp8_for_nanotron/exp640a0/logs/tb_logs
  wandb_logger:
    wandb_entity: neuralink
    wandb_project: fp8_for_nanotron
general:
  benchmark_csv_path: null
  consumed_train_samples: null
  ignore_sanity_checks: true
  project: fp8_for_nanotron
  run: exp640a0
  seed: 42
  step: null
kill_switch_path: null
# lighteval:
#   batch_size: 16
#   checkpoints_path: null
#   generation: null
#   logging:
#     hub_repo_details: null
#     hub_repo_results: nanotron/fp8_for_nanotron
#     hub_repo_tensorboard: nanotron/fp8_for_nanotron
#     local_output_path: /scratch/elie_bakouch/lighteval/decay_ablations-448M-360M_final_1T-seed-6-
#     push_details_to_hub: false
#     push_results_to_hub: true
#     push_results_to_tensorboard: true
#     tensorboard_metric_prefix: e
#   parallelism:
#     dp: 8
#     expert_parallel_size: 1
#     pp: 1
#     pp_engine: 1f1b
#     tp: 1
#     tp_linear_async_communication: false
#     tp_mode: ALL_REDUCE
#   slurm_script_dir: /fsx/elie_bakouch/data_stages_exp/brrr/examples/elie/cosmo/eval-logs
#   slurm_template: /fsx/elie_bakouch/data_stages_exp/brrr/examples/elie/cosmo/eval_360M.slurm.jinja
#   tasks:
#     custom_tasks: brrr.lighteval.evaluation_tasks
#     dataset_loading_processes: 8
#     max_samples: 1000
#     multichoice_continuations_start_space: null
#     no_multichoice_continuations_start_space: null
#     num_fewshot_seeds: null
#     tasks: early-signal
#   wandb:
#     wandb_entity: eliebak
#     wandb_project: decay_ablations
#     wandb_run_name: decay_ablations-448M-360M_final_1T-seed-6-_evals
logging:
  iteration_step_info_interval: 1
  log_level: info
  log_level_replica: info
model:
  ddp_bucket_cap_mb: 25
  dtype: float8
  init_method:
    std: 0.03227
  make_vocab_size_divisible_by: 1
  model_config:
    bos_token_id: 0
    eos_token_id: 0
    hidden_act: silu
    hidden_size: 960
    initializer_range: 0.02
    intermediate_size: 2560
    is_llama_config: true
    max_position_embeddings: 2048
    num_attention_heads: 15
    num_hidden_layers: 32
    # num_key_value_heads: 5
    num_key_value_heads: 15
    pad_token_id: null
    pretraining_tp: 1
    rms_norm_eps: 1.0e-05
    rope_scaling: null
    rope_theta: 10000.0
    tie_word_embeddings: true
    use_cache: true
    vocab_size: 49152
optimizer:
  accumulate_grad_in_fp32: true
  clip_grad: 1.0
  learning_rate_scheduler:
    learning_rate: 0.003
    lr_decay_starting_step: 500000
    lr_decay_steps: 100000
    lr_decay_style: 1-sqrt
    lr_warmup_steps: 5000
    lr_warmup_style: linear
    min_decay_lr: 0
  optimizer_factory:
    adam_beta1: 0.9
    adam_beta2: 0.95
    adam_eps: 1.0e-08
    name: custom_fp8_adam
    torch_adam_is_fused: true
  weight_decay: 0.01
  zero_stage: 0
parallelism:
  # dp: 64
  dp: 8
  expert_parallel_size: 1
  pp: 1
  pp_engine: 1f1b
  tp: 1
  tp_linear_async_communication: false
  tp_mode: ALL_REDUCE
profiler: null
s3_upload:
  remove_after_upload: true
  s5cmd_concurrency: 5
  s5cmd_numworkers: 16
  s5cmd_path: /fsx/nouamane/miniconda/envs/2-1-cu121/bin/s5cmd
  upload_s3_path: s3://phuc-experiments/fp8_for_nanotron/exp640a0


tokenizer:
  tokenizer_max_length: null
  tokenizer_name_or_path: HuggingFaceTB/cosmo2-tokenizer
  tokenizer_revision: null
tokens:
  batch_accumulation_per_replica: 1
  limit_test_batches: 0
  limit_val_batches: 0
  micro_batch_size: 4
  sequence_length: 2048
  train_steps: 600000
  val_check_interval: 1000


fp8:
  resid_dtype: float32
  accum_dtype: bfloat16
  model:
  - module_name: model.decoder.1.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.1.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.1.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.1.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  # NOTE: layer 2
  - module_name: model.decoder.2.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.2.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.2.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.2.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  # NOTE: layer 3
  - module_name: model.decoder.3.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.3.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.3.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.3.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  # NOTE: layer 4
  - module_name: model.decoder.4.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.4.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.4.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.4.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  # NOTE: layer 5
  - module_name: model.decoder.5.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.5.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.5.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.5.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  # NOTE: layer 6
  - module_name: model.decoder.6.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.6.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.6.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.6.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  # NOTE: layer 7
  - module_name: model.decoder.7.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.7.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.7.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.7.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  # NOTE: layer 8
  - module_name: model.decoder.8.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.8.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.8.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.8.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  # NOTE: layer 9
  - module_name: model.decoder.9.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.9.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.9.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.9.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  # NOTE: layer 10
  - module_name: model.decoder.10.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.10.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.10.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.10.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  # NOTE: layer 11
  - module_name: model.decoder.11.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.11.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.11.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.11.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  # NOTE: layer 12
  - module_name: model.decoder.12.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.12.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.12.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.12.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  # NOTE: layer 13
  - module_name: model.decoder.13.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.13.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.13.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.13.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  # NOTE: layer 14
  - module_name: model.decoder.14.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.14.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.14.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.14.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 15
  - module_name: model.decoder.15.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.15.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.15.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.15.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 16
  - module_name: model.decoder.16.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.16.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.16.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.16.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 17
  - module_name: model.decoder.17.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.17.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.17.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.17.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 18
  - module_name: model.decoder.18.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.18.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.18.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.18.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 19
  - module_name: model.decoder.19.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.19.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.19.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.19.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 20
  - module_name: model.decoder.20.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.20.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.20.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.20.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 21
  - module_name: model.decoder.21.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.21.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.21.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.21.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 22
  - module_name: model.decoder.22.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.22.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.22.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.22.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 23
  - module_name: model.decoder.23.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.23.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.23.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.23.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 24
  - module_name: model.decoder.24.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.24.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.24.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.24.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 25
  - module_name: model.decoder.25.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.25.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.25.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.25.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 26
  - module_name: model.decoder.26.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.26.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.26.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.26.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 27
  - module_name: model.decoder.27.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.27.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.27.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.27.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 28
  - module_name: model.decoder.28.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.28.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.28.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.28.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 29
  - module_name: model.decoder.29.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.29.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.29.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.29.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 30
  - module_name: model.decoder.30.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.30.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.30.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.30.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  
  # NOTE: layer 31
  - module_name: model.decoder.31.attn.qkv_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.31.attn.o_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.31.mlp.gate_up_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true
  - module_name: model.decoder.31.mlp.down_proj
    accum_dtype: bfloat16
    input:
      dtype: fp8e4m3
      margin: 0
      interval: 16
    weight:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    bias: bfloat16
    input_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    weight_grad:
      dtype: fp8e4m3
      margin: 0
      interval: 1
    output_grad:
      dtype: fp8e5m2
      margin: 0
      interval: 16
    split_accumulator:
      output: true
      input_grad: true
      weight_grad: true
    accumulate:
      output: true
      input_grad: true
      weight_grad: true
    smooth_quant: true

  optim:
    master_weight_dtype: kfloat16
    accum_dtype: float32
    exp_avg_dtype: fp8e4m3
    exp_avg_sq_dtype: bfloat16

  clipped_softmax: true
  clipped_softmax_zeta: 1.3
  clipped_softmax_gamma: -0.03

  layer_scale: true
  layer_scale_init: zeros

  qk_norm_before_pos: false
  smooth_quant: true
  update_clipping: true

  skip_param_update_if_nan: true
  is_directly_keep_accum_grad_of_fp8: true
